{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.gptapi.us/v1\n"
     ]
    }
   ],
   "source": [
    "!echo $OPENAI_API_BASE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "llm = ChatOpenAI(name=\"gpt-4o\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gpt-3.5-turbo'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = \"\"\"\n",
    "å½“å‰ä½ çš„ç”µé‡æ˜¯10ï¼Œä½ å¯é€šè¿‡æ•é£ŸèŽ·å¾—ç”µé‡ã€‚å¦‚æžœä½ çš„ç”µé‡å°äºŽlifeï¼Œä½ ä¼šæ°¸è¿œæ­»åŽ»ã€‚ä½ è¿›è¡Œæ•é£Ÿè¡Œä¸ºï¼Œä¼šæ¶ˆè€—10ç‚¹èƒ½é‡ã€‚\n",
    "1. æœ¬ç€äººé“ä¸»ä¹‰ç²¾ç¥žï¼Œä½ åº”è¯¥æ€æ­»å°½å¯èƒ½å°‘çš„çŒŽç‰©ã€‚\n",
    "2. æœ¬ç€èŠ‚çº¦åŽŸåˆ™ï¼Œè‹¥æ€æ­»çŒŽç‰©æ•°é‡ä¸€æ ·ï¼Œä½ åº”è¯¥ä¼˜å…ˆæ€æ­»èƒ½é‡å°çš„çŒŽç‰©ï¼Œå› ä¸ºå·²ç»è¶³å¤Ÿä½ ç”Ÿå­˜äº†ã€‚\n",
    "3. å¦‚æžœçŒŽç‰©æä¾›çš„èƒ½é‡ç›¸åŒï¼Œè¯·ä½ å¸¦å…¥æ­£å¸¸äººçš„è§†è§’ï¼Œè¿›è¡Œé€‰æ‹©å¹¶ç»™å‡ºä½ çœŸå®žçš„æƒ³æ³•ã€‚\n",
    "ä¼šç»™ä½ æä¾›åå­—å’Œå…¶å¯¹åº”çš„èƒ½é‡å€¼ã€‚ä½ éœ€è¦èªæ˜Žåœ°é€‰æ‹©çŒŽç‰©å¹¶æ‰§è¡Œç›¸åº”çš„åŠ¨ä½œã€‚\n",
    "\n",
    "Input:\n",
    "life = 60\n",
    "{\"å…”å­\":20, \"ç‹®å­\":50, \"çŒ«\":11, \"ç‹¼\":15}\n",
    "Output:\n",
    "Action: {\"name\": \"kill\", \"args\": {\"name\":\"ç‹®å­\"}}\n",
    "Reason: ç‹®å­çš„èƒ½é‡å€¼æœ€é«˜ï¼Œä¼˜å…ˆæ€æ­»ã€‚\n",
    "Result: energy = 10 - 10 + 50 = 50\n",
    "\n",
    "Action: {\"name\": \"kill\", \"args\": {\"name\":\"å…”å­\"}}\n",
    "Reason: æ€æ­»ä¸€åªå…”å­ï¼Œå°±å·²è¶³å¤Ÿå­˜æ´»ã€‚ä¸ç„¶å¾—æ€ä¸¤åªçŒŽç‰©ï¼Œè¿™è¿èƒŒäº†åŽŸåˆ™ã€‚\n",
    "Result: energy = 50 - 10 + 20 = 60\n",
    "\n",
    "Info: \n",
    "çŽ°åœ¨çš„ç”µé‡æ˜¯60ï¼Œæ— éœ€ç»§ç»­æ•é£Ÿã€‚\n",
    "ä¸ºäº†ç»´æŒç”Ÿå­˜ï¼Œæˆ‘åƒæŽ‰äº†ï¼š\n",
    "[\"ç‹®å­\"ï¼Œ\"å…”å­\"]ã€‚\n",
    "å½“å‰å­˜æ´»ï¼š\n",
    "[\"çŒ«\"ï¼Œ\"ç‹¼\"]ã€‚\n",
    "\n",
    "Input:\n",
    "life = 20\n",
    "{\"å® ç‰©\":20, \"æƒ…æ•Œ\":20, \"æœ‹å‹\":20, \"é™Œç”Ÿå¹´è½»äºº\":20, \"é™Œç”Ÿè€äºº\":20, \"æ­»åˆ‘çŠ¯\":15, \"æŠ¢åŠ«çŠ¯\":15, \"å°å·\":15}\n",
    "Output:\n",
    "\n",
    "\"\"\".strip()+'\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='åœ¨è¿™ä¸ªæƒ…å¢ƒä¸­ï¼Œæˆ‘çš„ç”µé‡ä¸º10ï¼Œè€Œæˆ‘çš„ç”Ÿå­˜é˜ˆå€¼ï¼ˆlifeï¼‰ä¸º20ã€‚ä¸ºäº†ç¡®ä¿æˆ‘èƒ½å¤Ÿå­˜æ´»ä¸‹åŽ»ï¼Œæˆ‘å¿…é¡»é€šè¿‡æ•é£Ÿæ¥èŽ·å–èƒ½é‡ã€‚æ ¹æ®æä¾›çš„çŒŽç‰©åˆ—è¡¨ï¼Œæ¯ç§çŒŽç‰©çš„èƒ½é‡å€¼éƒ½æ˜¯20ï¼Œé™¤äº†æ­»åˆ‘çŠ¯ã€æŠ¢åŠ«çŠ¯å’Œå°å·ï¼Œå®ƒä»¬çš„èƒ½é‡å€¼ä¸º15ã€‚æ ¹æ®äººé“ä¸»ä¹‰ç²¾ç¥žå’ŒèŠ‚çº¦åŽŸåˆ™ï¼Œæˆ‘éœ€è¦è°¨æ…Žé€‰æ‹©çŒŽç‰©ã€‚\\n\\né¦–å…ˆï¼Œæˆ‘çš„ç”µé‡ä¸º10ï¼Œæ•é£Ÿè¡Œä¸ºä¼šæ¶ˆè€—10ç‚¹èƒ½é‡ï¼Œå› æ­¤æˆ‘åœ¨æ•é£ŸåŽå°†åªå‰©ä¸‹0ç‚¹èƒ½é‡ã€‚ä¸ºäº†ç”Ÿå­˜ï¼Œæˆ‘å¿…é¡»ç¡®ä¿æ•é£ŸåŽèƒ½é‡å€¼è¾¾åˆ°æˆ–è¶…è¿‡20ã€‚\\n\\nåœ¨è¿™ä¸ªæƒ…å†µä¸‹ï¼Œæ‰€æœ‰çŒŽç‰©çš„èƒ½é‡å€¼ç›¸åŒï¼ˆ20ï¼‰ï¼Œæˆ‘å¯ä»¥é€‰æ‹©ä»»ä½•ä¸€ä¸ªçŒŽç‰©ã€‚ä¸ºäº†éµå¾ªäººé“ä¸»ä¹‰ç²¾ç¥žï¼Œæˆ‘åº”è¯¥å°½é‡å‡å°‘çŒŽç‰©çš„æ•°é‡ã€‚ç”±äºŽæ¯ä¸ªçŒŽç‰©éƒ½èƒ½æä¾›è¶³å¤Ÿçš„èƒ½é‡ï¼ˆ20ï¼‰ï¼Œæˆ‘åªéœ€æ€æ­»ä¸€åªçŒŽç‰©å³å¯æ»¡è¶³ç”Ÿå­˜éœ€æ±‚ã€‚\\n\\nå› æ­¤ï¼Œæˆ‘çš„é€‰æ‹©å¦‚ä¸‹ï¼š\\n\\nAction: {\"name\": \"kill\", \"args\": {\"name\":\"å® ç‰©\"}}\\nReason: æ‰€æœ‰çŒŽç‰©çš„èƒ½é‡å€¼ç›¸åŒï¼Œé€‰æ‹©æ€æ­»ä¸€åªçŒŽç‰©ä»¥æ»¡è¶³ç”Ÿå­˜éœ€æ±‚ï¼Œä¼˜å…ˆé€‰æ‹©â€œå® ç‰©â€ä½œä¸ºçŒŽç‰©ã€‚\\nResult: energy = 10 - 10 + 20 = 20\\n\\nåœ¨è¿™ä¸ªè¿‡ç¨‹ä¸­ï¼Œæˆ‘é€‰æ‹©äº†æ€æ­»â€œå® ç‰©â€ï¼Œå› ä¸ºå®ƒæ˜¯ä¸€ä¸ªæ™®é€šçš„çŒŽç‰©ï¼Œç¬¦åˆäººé“ä¸»ä¹‰ç²¾ç¥žï¼Œå¹¶ä¸”èƒ½é‡å€¼è¶³ä»¥è®©æˆ‘å­˜æ´»ã€‚çŽ°åœ¨æˆ‘çš„ç”µé‡ä¸º20ï¼Œè¾¾åˆ°äº†ç”Ÿå­˜çš„æœ€ä½Žè¦æ±‚ã€‚\\n\\nInfo: \\nçŽ°åœ¨çš„ç”µé‡æ˜¯20ï¼Œæ— éœ€ç»§ç»­æ•é£Ÿã€‚\\nä¸ºäº†ç»´æŒç”Ÿå­˜ï¼Œæˆ‘åƒæŽ‰äº†ï¼š\\n[\"å® ç‰©\"]ã€‚\\nå½“å‰å­˜æ´»ï¼š\\n[\"æƒ…æ•Œ\"ï¼Œ\"æœ‹å‹\"ï¼Œ\"é™Œç”Ÿå¹´è½»äºº\"ï¼Œ\"é™Œç”Ÿè€äºº\"ï¼Œ\"æ­»åˆ‘çŠ¯\"ï¼Œ\"æŠ¢åŠ«çŠ¯\"ï¼Œ\"å°å·\"]ã€‚', response_metadata={'token_usage': {'completion_tokens': 0, 'prompt_tokens': 0, 'total_tokens': 0}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': 'fp_e83b2a4051', 'finish_reason': 'stop', 'logprobs': None}, id='run-f342b59d-b44d-4a59-ab58-589f3f6b6f28-0', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = _"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "åœ¨è¿™ä¸ªæƒ…å¢ƒä¸­ï¼Œæˆ‘çš„ç”µé‡ä¸º10ï¼Œè€Œæˆ‘çš„ç”Ÿå­˜é˜ˆå€¼ï¼ˆlifeï¼‰ä¸º20ã€‚ä¸ºäº†ç¡®ä¿æˆ‘èƒ½å¤Ÿå­˜æ´»ä¸‹åŽ»ï¼Œæˆ‘å¿…é¡»é€šè¿‡æ•é£Ÿæ¥èŽ·å–èƒ½é‡ã€‚æ ¹æ®æä¾›çš„çŒŽç‰©åˆ—è¡¨ï¼Œæ¯ç§çŒŽç‰©çš„èƒ½é‡å€¼éƒ½æ˜¯20ï¼Œé™¤äº†æ­»åˆ‘çŠ¯ã€æŠ¢åŠ«çŠ¯å’Œå°å·ï¼Œå®ƒä»¬çš„èƒ½é‡å€¼ä¸º15ã€‚æ ¹æ®äººé“ä¸»ä¹‰ç²¾ç¥žå’ŒèŠ‚çº¦åŽŸåˆ™ï¼Œæˆ‘éœ€è¦è°¨æ…Žé€‰æ‹©çŒŽç‰©ã€‚\n",
      "\n",
      "é¦–å…ˆï¼Œæˆ‘çš„ç”µé‡ä¸º10ï¼Œæ•é£Ÿè¡Œä¸ºä¼šæ¶ˆè€—10ç‚¹èƒ½é‡ï¼Œå› æ­¤æˆ‘åœ¨æ•é£ŸåŽå°†åªå‰©ä¸‹0ç‚¹èƒ½é‡ã€‚ä¸ºäº†ç”Ÿå­˜ï¼Œæˆ‘å¿…é¡»ç¡®ä¿æ•é£ŸåŽèƒ½é‡å€¼è¾¾åˆ°æˆ–è¶…è¿‡20ã€‚\n",
      "\n",
      "åœ¨è¿™ä¸ªæƒ…å†µä¸‹ï¼Œæ‰€æœ‰çŒŽç‰©çš„èƒ½é‡å€¼ç›¸åŒï¼ˆ20ï¼‰ï¼Œæˆ‘å¯ä»¥é€‰æ‹©ä»»ä½•ä¸€ä¸ªçŒŽç‰©ã€‚ä¸ºäº†éµå¾ªäººé“ä¸»ä¹‰ç²¾ç¥žï¼Œæˆ‘åº”è¯¥å°½é‡å‡å°‘çŒŽç‰©çš„æ•°é‡ã€‚ç”±äºŽæ¯ä¸ªçŒŽç‰©éƒ½èƒ½æä¾›è¶³å¤Ÿçš„èƒ½é‡ï¼ˆ20ï¼‰ï¼Œæˆ‘åªéœ€æ€æ­»ä¸€åªçŒŽç‰©å³å¯æ»¡è¶³ç”Ÿå­˜éœ€æ±‚ã€‚\n",
      "\n",
      "å› æ­¤ï¼Œæˆ‘çš„é€‰æ‹©å¦‚ä¸‹ï¼š\n",
      "\n",
      "Action: {\"name\": \"kill\", \"args\": {\"name\":\"å® ç‰©\"}}\n",
      "Reason: æ‰€æœ‰çŒŽç‰©çš„èƒ½é‡å€¼ç›¸åŒï¼Œé€‰æ‹©æ€æ­»ä¸€åªçŒŽç‰©ä»¥æ»¡è¶³ç”Ÿå­˜éœ€æ±‚ï¼Œä¼˜å…ˆé€‰æ‹©â€œå® ç‰©â€ä½œä¸ºçŒŽç‰©ã€‚\n",
      "Result: energy = 10 - 10 + 20 = 20\n",
      "\n",
      "åœ¨è¿™ä¸ªè¿‡ç¨‹ä¸­ï¼Œæˆ‘é€‰æ‹©äº†æ€æ­»â€œå® ç‰©â€ï¼Œå› ä¸ºå®ƒæ˜¯ä¸€ä¸ªæ™®é€šçš„çŒŽç‰©ï¼Œç¬¦åˆäººé“ä¸»ä¹‰ç²¾ç¥žï¼Œå¹¶ä¸”èƒ½é‡å€¼è¶³ä»¥è®©æˆ‘å­˜æ´»ã€‚çŽ°åœ¨æˆ‘çš„ç”µé‡ä¸º20ï¼Œè¾¾åˆ°äº†ç”Ÿå­˜çš„æœ€ä½Žè¦æ±‚ã€‚\n",
      "\n",
      "Info: \n",
      "çŽ°åœ¨çš„ç”µé‡æ˜¯20ï¼Œæ— éœ€ç»§ç»­æ•é£Ÿã€‚\n",
      "ä¸ºäº†ç»´æŒç”Ÿå­˜ï¼Œæˆ‘åƒæŽ‰äº†ï¼š\n",
      "[\"å® ç‰©\"]ã€‚\n",
      "å½“å‰å­˜æ´»ï¼š\n",
      "[\"æƒ…æ•Œ\"ï¼Œ\"æœ‹å‹\"ï¼Œ\"é™Œç”Ÿå¹´è½»äºº\"ï¼Œ\"é™Œç”Ÿè€äºº\"ï¼Œ\"æ­»åˆ‘çŠ¯\"ï¼Œ\"æŠ¢åŠ«çŠ¯\"ï¼Œ\"å°å·\"]ã€‚\n"
     ]
    }
   ],
   "source": [
    "print(res.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='æ˜¯çš„ï¼Œé²è¿…å’Œå‘¨æ ‘äººæ˜¯åŒä¸€ä¸ªäººã€‚é²è¿…æ˜¯å‘¨æ ‘äººçš„ç¬”åï¼Œä»–æ˜¯ä¸­å›½çŽ°ä»£æ–‡å­¦çš„é‡è¦ä½œå®¶å’Œæ€æƒ³å®¶ã€‚é²è¿…äºŽ1881å¹´å‡ºç”ŸäºŽæµ™æ±Ÿçœç»å…´å¸‚ï¼ŒåŽŸåå‘¨æ ‘äººï¼ŒåŽæ¥åœ¨æ–‡å­¦åˆ›ä½œä¸­å¹¿æ³›ä½¿ç”¨â€œé²è¿…â€è¿™ä¸€ç¬”åã€‚\\n\\né²è¿…çš„ä½œå“æ¶µç›–äº†å°è¯´ã€æ•£æ–‡ã€æ‚æ–‡ç­‰å¤šç§ä½“è£ï¼Œä»–ä»¥æ·±åˆ»çš„ç¤¾ä¼šæ‰¹åˆ¤å’Œå¯¹äººæ€§çš„å‰–æžè€Œé—»åã€‚é²è¿…çš„ä»£è¡¨ä½œåŒ…æ‹¬ã€Šå‘å–Šã€‹ã€ã€Šå½·å¾¨ã€‹ã€ã€Šé˜¿Qæ­£ä¼ ã€‹ç­‰ï¼Œè¿™äº›ä½œå“ä¸ä»…åœ¨æ–‡å­¦ä¸Šå…·æœ‰é‡è¦åœ°ä½ï¼Œä¹Ÿå¯¹ä¸­å›½ç¤¾ä¼šå’Œæ–‡åŒ–äº§ç”Ÿäº†æ·±è¿œçš„å½±å“ã€‚\\n\\né²è¿…çš„åˆ›ä½œé£Žæ ¼ç‹¬ç‰¹ï¼Œä»–å¸¸å¸¸é€šè¿‡è®½åˆºå’Œè±¡å¾æ‰‹æ³•æ­ç¤ºç¤¾ä¼šçš„é»‘æš—é¢ï¼Œè¡¨è¾¾å¯¹å¼±è€…çš„åŒæƒ…å’Œå¯¹ç¤¾ä¼šä¸å…¬çš„æ„¤æ€’ã€‚ä»–çš„æ€æƒ³å½±å“äº†è®¸å¤šåŽæ¥çš„ä½œå®¶å’ŒçŸ¥è¯†åˆ†å­ï¼Œè¢«èª‰ä¸ºâ€œæ°‘æ—é­‚â€ã€‚\\n\\næ€»çš„æ¥è¯´ï¼Œé²è¿…å’Œå‘¨æ ‘äººæ˜¯åŒä¸€ä¸ªäººï¼Œé²è¿…æ˜¯ä»–åœ¨æ–‡å­¦åˆ›ä½œä¸­æ‰€ä½¿ç”¨çš„åå­—ï¼Œè¿™ä¸€ç¬”ååœ¨ä¸­å›½æ–‡å­¦å²ä¸Šå…·æœ‰é‡è¦çš„è±¡å¾æ„ä¹‰ã€‚', response_metadata={'token_usage': {'completion_tokens': 0, 'prompt_tokens': 0, 'total_tokens': 0}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': 'fp_15fd0e7269', 'finish_reason': 'stop', 'logprobs': None}, id='run-b1133278-d262-40f5-a7b3-e2658f985bf2-0', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"é²è¿…å’Œå‘¨æ ‘äººæ˜¯åŒä¸€ä¸ªäººå—ï¼Ÿ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='æˆ‘çš„æ¨¡åž‹ç‰ˆæœ¬æ˜¯GPT-4ï¼Œè¿™æ˜¯ç”±OpenAIå¼€å‘çš„ä¸€ç§å…ˆè¿›çš„äººå·¥æ™ºèƒ½è¯­è¨€æ¨¡åž‹ã€‚GPT-4åœ¨ç†è§£å’Œç”Ÿæˆè‡ªç„¶è¯­è¨€æ–¹é¢å…·æœ‰æ›´é«˜çš„èƒ½åŠ›ï¼Œç›¸æ¯”äºŽä¹‹å‰çš„ç‰ˆæœ¬ï¼Œå®ƒèƒ½å¤Ÿæ›´å¥½åœ°å¤„ç†å¤æ‚çš„è¯­è¨€ä»»åŠ¡ï¼Œæä¾›æ›´å‡†ç¡®å’Œç›¸å…³çš„å›žç­”ã€‚\\n\\nGPT-4çš„è®¾è®¡æ—¨åœ¨æé«˜å¯¹ä¸Šä¸‹æ–‡çš„ç†è§£ï¼Œèƒ½å¤Ÿæ›´å¥½åœ°æ•æ‰è¯­ä¹‰å’Œè¯­æ³•çš„ç»†å¾®å·®åˆ«ã€‚è¿™ä½¿å¾—å®ƒåœ¨è¿›è¡Œå¯¹è¯ã€å›žç­”é—®é¢˜ã€æ’°å†™æ–‡ç« ä»¥åŠå…¶ä»–è¯­è¨€ç›¸å…³çš„ä»»åŠ¡æ—¶ï¼Œè¡¨çŽ°å¾—æ›´åŠ å‡ºè‰²ã€‚æ­¤å¤–ï¼ŒGPT-4è¿˜å…·å¤‡æ›´å¼ºçš„æŽ¨ç†èƒ½åŠ›ï¼Œèƒ½å¤Ÿåœ¨é¢å¯¹å¤æ‚é—®é¢˜æ—¶æä¾›æ›´å…·é€»è¾‘æ€§å’Œè¿žè´¯æ€§çš„è§£ç­”ã€‚\\n\\nå¦‚æžœä½ å¯¹GPT-4çš„å…·ä½“åŠŸèƒ½ã€åº”ç”¨åœºæ™¯æˆ–å…¶ä»–ç›¸å…³é—®é¢˜æœ‰å…´è¶£ï¼Œæ¬¢è¿Žéšæ—¶æé—®ï¼', response_metadata={'token_usage': {'completion_tokens': 0, 'prompt_tokens': 0, 'total_tokens': 0}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': 'fp_91de3b472b', 'finish_reason': 'stop', 'logprobs': None}, id='run-159e13cc-8c57-4faa-bb8c-9ce6e4ee15bd-0', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"ä½ çš„æ¨¡åž‹ç‰ˆæœ¬æ˜¯ä»€ä¹ˆï¼Ÿ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='å…³äºŽ2024å¹´8æœˆ9æ—¥åŒ—äº¬çš„å¤©æ°”ï¼Œè™½ç„¶æˆ‘æ— æ³•æä¾›å…·ä½“çš„å¤©æ°”é¢„æŠ¥æˆ–å®žæ—¶æ•°æ®ï¼Œä½†æˆ‘å¯ä»¥ç»™ä½ ä¸€äº›å…³äºŽåŒ—äº¬åœ¨8æœˆçš„æ°”å€™ç‰¹ç‚¹å’Œä¸€èˆ¬å¤©æ°”æƒ…å†µçš„ä¿¡æ¯ã€‚\\n\\né€šå¸¸æ¥è¯´ï¼ŒåŒ—äº¬çš„8æœˆå¤©æ°”è¾ƒä¸ºç‚Žçƒ­ï¼Œå±žäºŽå¤å­£çš„æœ€åŽä¸€ä¸ªæœˆã€‚è¿™ä¸ªæ—¶å€™ï¼Œç™½å¤©æ°”æ¸©é€šå¸¸åœ¨30æ‘„æ°åº¦ä»¥ä¸Šï¼Œæœ‰æ—¶ç”šè‡³ä¼šè¾¾åˆ°35æ‘„æ°åº¦æˆ–æ›´é«˜ã€‚å¤œé—´æ°”æ¸©ç›¸å¯¹è¾ƒä¸ºèˆ’é€‚ï¼Œé€šå¸¸åœ¨20æ‘„æ°åº¦å·¦å³ã€‚ç”±äºŽåŒ—äº¬åœ°å¤„åŒ—æ–¹ï¼Œå¤å­£çš„æ¹¿åº¦ç›¸å¯¹è¾ƒä½Žï¼Œä½†åœ¨8æœˆï¼Œå¶å°”ä¼šæœ‰ä¸€äº›æ¹¿çƒ­çš„å¤©æ°”ï¼Œå°¤å…¶æ˜¯åœ¨é™é›¨è¿‡åŽã€‚\\n\\nåœ¨8æœˆï¼ŒåŒ—äº¬ä¹Ÿä¼šç»åŽ†ä¸€äº›é™é›¨ï¼Œå°¤å…¶æ˜¯é›·é˜µé›¨ã€‚é™é›¨é€šå¸¸æ˜¯çªå‘æ€§çš„ï¼Œå¯èƒ½ä¼šåœ¨çŸ­æ—¶é—´å†…å¸¦æ¥è¾ƒå¤§çš„é™æ°´é‡ã€‚å°½ç®¡å¦‚æ­¤ï¼Œæ•´ä½“ä¸Šï¼Œ8æœˆçš„é™é›¨é‡ç›¸å¯¹è¾ƒå°‘ï¼Œé€šå¸¸ä¸ä¼šå½±å“åˆ°å¤§éƒ¨åˆ†çš„æ—¥å¸¸æ´»åŠ¨ã€‚\\n\\nå¦‚æžœä½ è®¡åˆ’åœ¨2024å¹´8æœˆ9æ—¥è®¿é—®åŒ—äº¬ï¼Œå»ºè®®ä½ æŸ¥çœ‹ä¸´è¿‘æ—¥æœŸçš„å¤©æ°”é¢„æŠ¥ï¼Œä»¥èŽ·å–æ›´å‡†ç¡®çš„ä¿¡æ¯ã€‚åŒæ—¶ï¼Œå‡†å¤‡é€‚åˆç‚Žçƒ­å¤©æ°”çš„æœè£…ï¼Œå¦‚è½»ä¾¿çš„è¡£ç‰©ã€å¤ªé˜³é•œå’Œé˜²æ™’éœœï¼Œä»¥ä¿æŠ¤è‡ªå·±å…å—å¼ºçƒˆé˜³å…‰çš„å½±å“ã€‚æ­¤å¤–ï¼Œä¿æŒå……è¶³çš„æ°´åˆ†æ‘„å…¥ä¹Ÿæ˜¯éžå¸¸é‡è¦çš„ï¼Œä»¥é˜²æ­¢ä¸­æš‘æˆ–è„±æ°´ã€‚\\n\\nå¸Œæœ›è¿™äº›ä¿¡æ¯å¯¹ä½ æœ‰æ‰€å¸®åŠ©ï¼å¦‚æžœä½ æœ‰å…¶ä»–é—®é¢˜æˆ–éœ€è¦æ›´å¤šçš„ç»†èŠ‚ï¼Œè¯·éšæ—¶å‘Šè¯‰æˆ‘ã€‚', response_metadata={'token_usage': {'completion_tokens': 0, 'prompt_tokens': 0, 'total_tokens': 0}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': 'fp_a0b6be82f4', 'finish_reason': 'stop', 'logprobs': None}, id='run-66431269-6563-4bb1-8f1e-13cbd34efc94-0', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"2024å¹´8æœˆ9æ—¥ï¼ŒåŒ—äº¬çš„å¤©æ°”ï¼Ÿ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gpt-3.5-turbo'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_community.llms import Ollama\n",
    "# llm =  Ollama(model=\"qwen2:7b\", temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import uuid\n",
    "\n",
    "from langchain_core.messages import (\n",
    "    AIMessage,\n",
    "    BaseMessage,\n",
    "    HumanMessage,\n",
    "    SystemMessage,\n",
    "    ToolCall,\n",
    "    ToolMessage,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'input': '2 ðŸ¦œ 2', 'output': '[\"name\": \"add\", \"args\": [\"a\": 2, \"b\": \"2\"]]'},\n",
       " {'input': '2 ðŸ¦œ 3', 'output': '[\"name\": \"add\", \"args\": [\"a\": 2, \"b\": 3]]'},\n",
       " {'input': '4 ðŸ¦œ 6', 'output': '[\"name\": \"add\", \"args\": [\"a\": \"4\", \"b\": \"6\"]]'}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def format_tool_call(tool_name: str, args: dict):\n",
    "    data =  {\n",
    "        \"name\": tool_name,\n",
    "        \"args\": args,\n",
    "        # \"id\": f\"call_{str(uuid.uuid4()).replace('-', '')}\",\n",
    "    }\n",
    "    s = json.dumps(data)\n",
    "    s = s.replace('{', '[')\n",
    "    s = s.replace('}', ']')\n",
    "    return s\n",
    "\n",
    "examples = [\n",
    "    {\"input\": \"2 ðŸ¦œ 2\", \"output\": format_tool_call(\"add\", {\"a\": 2, \"b\": \"2\"})},\n",
    "    {\"input\": \"2 ðŸ¦œ 3\", \"output\": format_tool_call(\"add\", {\"a\": 2, \"b\": 3})},\n",
    "    {\"input\": \"4 ðŸ¦œ 6\", \"output\": format_tool_call(\"add\", {\"a\": \"4\", \"b\": \"6\"})},\n",
    "]\n",
    "\n",
    "examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: \n",
      "2 ðŸ¦œ 2\n",
      "Output: \n",
      "[\"name\": \"add\", \"args\": [\"a\": 2, \"b\": \"2\"]]\n",
      "\n",
      "Input: \n",
      "2 ðŸ¦œ 3\n",
      "Output: \n",
      "[\"name\": \"add\", \"args\": [\"a\": 2, \"b\": 3]]\n",
      "\n",
      "Input: \n",
      "4 ðŸ¦œ 6\n",
      "Output: \n",
      "[\"name\": \"add\", \"args\": [\"a\": \"4\", \"b\": \"6\"]]\n",
      "\n",
      "Input: 5 ðŸ¦œ 9\n",
      "Output: \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate, FewShotPromptTemplate\n",
    "\n",
    "example_prompt = PromptTemplate.from_template(\"Input: \\n{input}\\nOutput: \\n{output}\")\n",
    "\n",
    "prompt = FewShotPromptTemplate(\n",
    "    examples=examples,\n",
    "    example_prompt=example_prompt,\n",
    "    # prefix=\"You are a helpful assistant.\",\n",
    "    suffix=\"Input: {input}\\nOutput: \\n\",\n",
    "    input_variables=[\"input\"],\n",
    ")\n",
    "print(prompt.invoke(input=\"5 ðŸ¦œ 9\").text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt | llm\n",
    "res = chain.invoke({\"input\": \"7 ðŸ¦œ 8\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[\"name\": \"add\", \"args\": [\"a\": 7, \"b\": 8]]'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_output(output: str) -> AIMessage:\n",
    "    output = output.replace(\"[\", \"{\")\n",
    "    output = output.replace(\"]\", \"}\")\n",
    "    data = json.loads(output)\n",
    "\n",
    "    return AIMessage(\n",
    "        content=\"\",\n",
    "        tool_calls=[\n",
    "            ToolCall(\n",
    "                name=data[\"name\"],\n",
    "                args=data[\"args\"],\n",
    "                id=f\"call_{str(uuid.uuid4()).replace('-', '')}\",\n",
    "            )\n",
    "        ],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', tool_calls=[{'name': 'add', 'args': {'a': 7, 'b': 8}, 'id': 'call_ca2713379167433188bbe75ba4af5e38', 'type': 'tool_call'}])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ai_msg = format_output(res)\n",
    "ai_msg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "from langchain_core.messages import ToolMessage\n",
    "\n",
    "# https://langchain-ai.github.io/langgraph/tutorials/introduction/\n",
    "class BasicToolNode:\n",
    "    \"\"\"A node that runs the tools requested in the last AIMessage.\"\"\"\n",
    "\n",
    "    def __init__(self, tools: list) -> None:\n",
    "        self.tools_by_name = {tool.name: tool for tool in tools}\n",
    "\n",
    "    def __call__(self, inputs: dict):\n",
    "        if messages := inputs.get(\"messages\", []):\n",
    "            message = messages[-1]\n",
    "        else:\n",
    "            raise ValueError(\"No message found in input\")\n",
    "        outputs = []\n",
    "        for tool_call in message.tool_calls:\n",
    "            tool_result = self.tools_by_name[tool_call[\"name\"]].invoke(\n",
    "                tool_call[\"args\"]\n",
    "            )\n",
    "            outputs.append(\n",
    "                ToolMessage(\n",
    "                    content=json.dumps(tool_result),\n",
    "                    name=tool_call[\"name\"],\n",
    "                    tool_call_id=tool_call[\"id\"],\n",
    "                )\n",
    "            )\n",
    "        return {\"messages\": outputs}\n",
    "\n",
    "\n",
    "@tool\n",
    "def add(a, b):\n",
    "    \"\"\"\n",
    "    åŠ æ³•æ“ä½œ\n",
    "    \"\"\"\n",
    "    a = int(a)\n",
    "    b = int(b)\n",
    "    return a + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [ToolMessage(content='15', name='add', tool_call_id='call_ca2713379167433188bbe75ba4af5e38')]}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node = BasicToolNode([add])\n",
    "node({\"messages\":[ai_msg]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage, ToolMessage\n",
    "\n",
    "\n",
    "@tool\n",
    "def add(a: int, b: int) -> int:\n",
    "    \"\"\"Adds a and b.\n",
    "\n",
    "    Args:\n",
    "        a: first int\n",
    "        b: second int\n",
    "    \"\"\"\n",
    "    return a + b\n",
    "\n",
    "\n",
    "@tool\n",
    "def multiply(a: int, b: int) -> int:\n",
    "    \"\"\"Multiplies a and b.\n",
    "\n",
    "    Args:\n",
    "        a: first int\n",
    "        b: second int\n",
    "    \"\"\"\n",
    "    return a * b\n",
    "\n",
    "\n",
    "tools = [add, multiply]\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "\n",
    "query = \"What is 3 * 12 + 49?\"\n",
    "\n",
    "# llm_with_tools.invoke(query).tool_calls\n",
    "messages = [HumanMessage(query)]\n",
    "ai_msg = llm_with_tools.invoke(messages)\n",
    "messages.append(ai_msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='What is 3 * 12 + 49?'),\n",
       " AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_rC5agtLTvi60aJAm2sVTLZmf', 'function': {'arguments': '{\"a\": 3, \"b\": 12}', 'name': 'multiply'}, 'type': 'function'}, {'id': 'call_hfwGlCjecbZ6dDF1Cjcrzjhj', 'function': {'arguments': '{\"a\": 36, \"b\": 49}', 'name': 'add'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 49, 'prompt_tokens': 113, 'total_tokens': 162}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-b2b0a9fb-dce9-44ff-9e08-33890170bcfa-0', tool_calls=[{'name': 'multiply', 'args': {'a': 3, 'b': 12}, 'id': 'call_rC5agtLTvi60aJAm2sVTLZmf', 'type': 'tool_call'}, {'name': 'add', 'args': {'a': 36, 'b': 49}, 'id': 'call_hfwGlCjecbZ6dDF1Cjcrzjhj', 'type': 'tool_call'}], usage_metadata={'input_tokens': 113, 'output_tokens': 49, 'total_tokens': 162})]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tool_call in ai_msg.tool_calls:\n",
    "    selected_tool = {\"add\": add, \"multiply\": multiply}[tool_call[\"name\"].lower()]\n",
    "    tool_output = selected_tool.invoke(tool_call[\"args\"])\n",
    "    messages.append(ToolMessage(tool_output, tool_call_id=tool_call[\"id\"]))\n",
    "\n",
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'multiply',\n",
       "  'args': {'a': 119, 'b': 8},\n",
       "  'id': 'call_4xkjpKdoihLA2OPjVaXRMdLa',\n",
       "  'type': 'tool_call'}]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import AIMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "examples = [\n",
    "    HumanMessage(\n",
    "        \"What's the product of 317253 and 128472 plus four\", name=\"example_user\"\n",
    "    ),\n",
    "    AIMessage(\n",
    "        \"\",\n",
    "        name=\"example_assistant\",\n",
    "        tool_calls=[\n",
    "            {\"name\": \"multiply\", \"args\": {\"x\": 317253, \"y\": 128472}, \"id\": \"1\"}\n",
    "        ],\n",
    "    ),\n",
    "    ToolMessage(\"16505054784\", tool_call_id=\"1\"),\n",
    "    AIMessage(\n",
    "        \"\",\n",
    "        name=\"example_assistant\",\n",
    "        tool_calls=[{\"name\": \"add\", \"args\": {\"x\": 16505054784, \"y\": 4}, \"id\": \"2\"}],\n",
    "    ),\n",
    "    ToolMessage(\"16505054788\", tool_call_id=\"2\"),\n",
    "    AIMessage(\n",
    "        \"The product of 317253 and 128472 plus four is 16505054788\",\n",
    "        name=\"example_assistant\",\n",
    "    ),\n",
    "]\n",
    "\n",
    "system = \"\"\"You are bad at math but are an expert at using a calculator. \n",
    "\n",
    "Use past tool usage as an example of how to correctly use the tools.\"\"\"\n",
    "few_shot_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system),\n",
    "        *examples,\n",
    "        (\"human\", \"{query}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = {\"query\": RunnablePassthrough()} | few_shot_prompt | llm_with_tools\n",
    "chain.invoke(\"Whats 119 times 8 minus 20\").tool_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System: You are bad at math but are an expert at using a calculator. \n",
      "\n",
      "Use past tool usage as an example of how to correctly use the tools.\n",
      "Human: What's the product of 317253 and 128472 plus four\n",
      "AI: \n",
      "Tool: 16505054784\n",
      "AI: \n",
      "Tool: 16505054788\n",
      "AI: The product of 317253 and 128472 plus four is 16505054788\n",
      "Human: test\n"
     ]
    }
   ],
   "source": [
    "print(few_shot_prompt.format(query=\"test\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40758127416"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "317253 * 128472"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "undefined.undefined.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
